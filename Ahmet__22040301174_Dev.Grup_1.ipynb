{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tıbbi Görüntü Sınıflandırması - ResNet18 Transfer Learning\n",
        "## Medical Image Classification using ResNet18\n",
        "\n",
        "Bu notebook, ResNet18 Transfer Learning kullanarak tıbbi görüntülerin sınıflandırılması için geliştirilmiştir.\n",
        "This notebook is developed for medical image classification using ResNet18 Transfer Learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms, datasets, models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
        "                            roc_auc_score, roc_curve, f1_score, precision_score, \n",
        "                            recall_score)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Kütüphaneler başarıyla yüklendi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Model Tanımı (Model Definition)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_transfer_learning_model(model_name='resnet18', num_classes=2, \n",
        "                                   pretrained=True, freeze_backbone=False):\n",
        "    model = None\n",
        "    \n",
        "    if model_name == 'resnet18':\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    elif model_name == 'resnet50':\n",
        "        model = models.resnet50(pretrained=pretrained)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model_name} desteklenmiyor\")\n",
        "    \n",
        "    if freeze_backbone:\n",
        "        if model_name in ['resnet18', 'resnet50']:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in model.fc.parameters():\n",
        "                param.requires_grad = True\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model(num_classes=2, input_channels=3, pretrained=False, \n",
        "                 model_type='transfer', model_name='resnet18', freeze_backbone=False):\n",
        "    if model_type == 'transfer':\n",
        "        if input_channels != 3:\n",
        "            raise ValueError(\"Transfer Learning renkli görüntüler gerektirir (3 kanal)\")\n",
        "        model = create_transfer_learning_model(\n",
        "            model_name=model_name,\n",
        "            num_classes=num_classes,\n",
        "            pretrained=pretrained,\n",
        "            freeze_backbone=freeze_backbone\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Bu notebook sadece Transfer Learning destekler\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "print(\"✓ Model fonksiyonları tanımlandı!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Veri Yükleme Fonksiyonları (Data Loading Functions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_loaders(data_dir, batch_size=32, img_size=224, use_weighted_sampler=False, num_workers=4):\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((int(img_size * 1.1), int(img_size * 1.1))),\n",
        "        transforms.RandomCrop(img_size),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomGrayscale(p=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                           std=[0.229, 0.224, 0.225]),\n",
        "        transforms.RandomErasing(p=0.1)\n",
        "    ])\n",
        "    \n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                           std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        root=os.path.join(data_dir, 'train'),\n",
        "        transform=train_transform\n",
        "    )\n",
        "    \n",
        "    val_dataset = datasets.ImageFolder(\n",
        "        root=os.path.join(data_dir, 'val'),\n",
        "        transform=val_transform\n",
        "    )\n",
        "    \n",
        "    train_sampler = None\n",
        "    class_weights = None\n",
        "    \n",
        "    if use_weighted_sampler:\n",
        "        class_counts = {}\n",
        "        for idx, (path, class_idx) in enumerate(train_dataset.samples):\n",
        "            class_counts[class_idx] = class_counts.get(class_idx, 0) + 1\n",
        "        \n",
        "        total_samples = sum(class_counts.values())\n",
        "        num_classes = len(class_counts)\n",
        "        class_weights = [total_samples / (num_classes * count) for count in class_counts.values()]\n",
        "        \n",
        "        sample_weights = [class_weights[class_idx] for _, class_idx in train_dataset.samples]\n",
        "        train_sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "        print(f\"✓ WeightedRandomSampler etkinleştirildi\")\n",
        "        print(f\"  Ağırlıklar: {dict(zip(train_dataset.classes, class_weights))}\")\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(train_sampler is None),\n",
        "        sampler=train_sampler,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    \n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    \n",
        "    if not class_weights:\n",
        "        class_counts = {}\n",
        "        for _, class_idx in train_dataset.samples:\n",
        "            class_counts[class_idx] = class_counts.get(class_idx, 0) + 1\n",
        "        total_samples = sum(class_counts.values())\n",
        "        num_classes = len(class_counts)\n",
        "        class_weights = [total_samples / (num_classes * count) for count in class_counts.values()]\n",
        "    \n",
        "    return train_loader, val_loader, train_dataset.classes, class_weights\n",
        "\n",
        "print(\"✓ Veri yükleme fonksiyonları tanımlandı!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Eğitim Fonksiyonları (Training Functions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    progress_bar = tqdm(train_loader, desc='Training')\n",
        "    for images, labels in progress_bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        \n",
        "        progress_bar.set_postfix({'loss': loss.item()})\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(val_loader, desc='Validation')\n",
        "        for images, labels in progress_bar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            \n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            \n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    \n",
        "    all_probs = np.array(all_probs)\n",
        "    \n",
        "    if len(np.unique(all_labels)) == 2:\n",
        "        auc_roc = roc_auc_score(all_labels, all_probs[:, 1])\n",
        "    else:\n",
        "        auc_roc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='weighted')\n",
        "    \n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels, all_probs, {\n",
        "        'auc_roc': auc_roc,\n",
        "        'f1_score': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "print(\"✓ Eğitim fonksiyonları tanımlandı!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Görselleştirme Fonksiyonları (Visualization Functions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_history(history, save_path='training_history.png'):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    \n",
        "    axes[0, 0].plot(epochs, history['train_loss'], label='Eğitim Loss', marker='o')\n",
        "    axes[0, 0].plot(epochs, history['val_loss'], label='Doğrulama Loss', marker='s')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].set_title('Eğitim ve Doğrulama Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    axes[0, 1].plot(epochs, history['train_acc'], label='Eğitim Accuracy', marker='o')\n",
        "    axes[0, 1].plot(epochs, history['val_acc'], label='Doğrulama Accuracy', marker='s')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].set_title('Eğitim ve Doğrulama Accuracy')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    if 'val_auc_roc' in history:\n",
        "        axes[1, 0].plot(epochs, history['val_auc_roc'], label='Doğrulama AUC-ROC', \n",
        "                       marker='s', color='green')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].set_ylabel('AUC-ROC')\n",
        "        axes[1, 0].set_title('Doğrulama AUC-ROC')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True)\n",
        "    \n",
        "    if 'val_f1_score' in history:\n",
        "        axes[1, 1].plot(epochs, history['val_f1_score'], label='Validation F1-Score', \n",
        "                       marker='s', color='purple')\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "        axes[1, 1].set_ylabel('F1-Score')\n",
        "        axes[1, 1].set_title('Validation F1-Score')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True)\n",
        "    else:\n",
        "        axes[1, 1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Eğitim grafiği kaydedildi: {save_path}\")\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, save_path='confusion_matrix.png'):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                cbar_kws={'label': 'Örnek Sayısı'})\n",
        "    plt.title('Karışıklık Matrisi (Confusion Matrix)')\n",
        "    plt.ylabel('Gerçek Etiket (True Label)')\n",
        "    plt.xlabel('Tahmin Edilen Etiket (Predicted Label)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Karışıklık matrisi kaydedildi: {save_path}\")\n",
        "\n",
        "\n",
        "def plot_roc_curve(y_true, y_probs, class_names, save_path='roc_curve.png'):\n",
        "    n_classes = len(class_names)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    if n_classes == 2:\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_probs[:, 1])\n",
        "        auc_score = roc_auc_score(y_true, y_probs[:, 1])\n",
        "        plt.plot(fpr, tpr, label=f'{class_names[1]} (AUC = {auc_score:.3f})', linewidth=2)\n",
        "    else:\n",
        "        for i in range(n_classes):\n",
        "            y_true_binary = (y_true == i).astype(int)\n",
        "            fpr, tpr, _ = roc_curve(y_true_binary, y_probs[:, i])\n",
        "            auc_score = roc_auc_score(y_true_binary, y_probs[:, i])\n",
        "            plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {auc_score:.3f})', linewidth=2)\n",
        "    \n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "    plt.title('ROC Eğrisi (ROC Curve)')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"ROC eğrisi kaydedildi: {save_path}\")\n",
        "\n",
        "print(\"✓ Görselleştirme fonksiyonları tanımlandı!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Eğitim Ayarları ve Başlatma (Training Configuration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = 'data'\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = None\n",
        "SAVE_DIR = 'checkpoints'\n",
        "\n",
        "USE_TRANSFER_LEARNING = True\n",
        "MODEL_NAME = 'resnet18'\n",
        "FREEZE_BACKBONE = True\n",
        "AUTO_UNFREEZE = True\n",
        "UNFREEZE_EPOCH = 5\n",
        "PRETRAINED = True\n",
        "\n",
        "USE_WEIGHTED_SAMPLER = True\n",
        "USE_WEIGHTED_LOSS = True\n",
        "\n",
        "USE_SCHEDULER = True\n",
        "SCHEDULER_TYPE = 'cosine'\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"=\"*70)\n",
        "print(f\"Cihaz kullanımı: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verileri Yükleme (Load Data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nVeriler yükleniyor...\")\n",
        "train_loader, val_loader, class_names, class_weights = get_data_loaders(\n",
        "    DATA_DIR,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    img_size=IMG_SIZE,\n",
        "    use_weighted_sampler=USE_WEIGHTED_SAMPLER,\n",
        "    num_workers=4\n",
        ")\n",
        "print(f\"\\n✓ Veriler başarıyla yüklendi!\")\n",
        "print(f\"  Sınıflar: {class_names}\")\n",
        "print(f\"  Eğitim görüntü sayısı: {len(train_loader.dataset)}\")\n",
        "print(f\"  Doğrulama görüntü sayısı: {len(val_loader.dataset)}\")\n",
        "\n",
        "detected_num_classes = len(class_names)\n",
        "if NUM_CLASSES is None:\n",
        "    NUM_CLASSES = detected_num_classes\n",
        "elif NUM_CLASSES != detected_num_classes:\n",
        "    print(f\"\\n⚠️  NUM_CLASSES değeri ({NUM_CLASSES}) ile verilerden okunan sınıf sayısı \"\n",
        "          f\"({detected_num_classes}) farklı. Verilerdeki değer kullanılacak.\")\n",
        "    NUM_CLASSES = detected_num_classes\n",
        "print(f\"  Toplam sınıf: {NUM_CLASSES}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Oluşturma (Create Model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\nModel oluşturuluyor...\")\n",
        "if USE_TRANSFER_LEARNING:\n",
        "    print(f\"  Model tipi: Transfer Learning ({MODEL_NAME})\")\n",
        "    model = create_model(\n",
        "        num_classes=NUM_CLASSES,\n",
        "        input_channels=3,\n",
        "        pretrained=PRETRAINED,\n",
        "        model_type='transfer',\n",
        "        model_name=MODEL_NAME,\n",
        "        freeze_backbone=FREEZE_BACKBONE\n",
        "    )\n",
        "else:\n",
        "    print(f\"  Model tipi: Özel CNN (sıfırdan)\")\n",
        "    model = create_model(\n",
        "        num_classes=NUM_CLASSES,\n",
        "        input_channels=3,\n",
        "        pretrained=False,\n",
        "        model_type='custom'\n",
        "    )\n",
        "\n",
        "model = model.to(device)\n",
        "backbone_unfrozen = not FREEZE_BACKBONE\n",
        "if FREEZE_BACKBONE:\n",
        "    print(\"  Backbone katmanları başlangıçta donduruldu.\")\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"  Toplam parametreler: {total_params:,}\")\n",
        "print(f\"  Eğitilebilir parametreler: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Loss, Optimizer ve Scheduler Ayarları\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if USE_WEIGHTED_LOSS and class_weights:\n",
        "    weights = torch.FloatTensor(class_weights).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    print(f\"\\n✓ Weighted Loss etkinleştirildi\")\n",
        "    print(f\"  Ağırlıklar: {dict(zip(class_names, class_weights))}\")\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
        "\n",
        "scheduler = None\n",
        "if USE_SCHEDULER:\n",
        "    if SCHEDULER_TYPE == 'plateau':\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=5\n",
        "        )\n",
        "    elif SCHEDULER_TYPE == 'cosine':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer, T_max=NUM_EPOCHS, eta_min=1e-6\n",
        "        )\n",
        "    elif SCHEDULER_TYPE == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(\n",
        "            optimizer, step_size=15, gamma=0.5\n",
        "        )\n",
        "    print(f\"\\n✓ Learning Rate Scheduler etkinleştirildi ({SCHEDULER_TYPE})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Eğitim Döngüsü (Training Loop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': [],\n",
        "    'val_auc_roc': [],\n",
        "    'val_f1_score': [],\n",
        "    'val_precision': [],\n",
        "    'val_recall': []\n",
        "}\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_val_auc = 0.0\n",
        "\n",
        "if AUTO_UNFREEZE and UNFREEZE_EPOCH > NUM_EPOCHS:\n",
        "    UNFREEZE_EPOCH = NUM_EPOCHS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Eğitim başlatılıyor...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    if FREEZE_BACKBONE and AUTO_UNFREEZE and not backbone_unfrozen and (epoch + 1) >= UNFREEZE_EPOCH:\n",
        "        print(f\"--> Epoch {epoch+1}: Backbone katmanları serbest bırakılıyor.\")\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "        backbone_unfrozen = True\n",
        "    \n",
        "    train_loss, train_acc = train_epoch(\n",
        "        model, train_loader, criterion, optimizer, device\n",
        "    )\n",
        "    \n",
        "    val_loss, val_acc, val_preds, val_labels, val_probs, metrics = validate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "    \n",
        "    if scheduler:\n",
        "        if SCHEDULER_TYPE == 'plateau':\n",
        "            scheduler.step(val_loss)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "    \n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_auc_roc'].append(metrics['auc_roc'])\n",
        "    history['val_f1_score'].append(metrics['f1_score'])\n",
        "    history['val_precision'].append(metrics['precision'])\n",
        "    history['val_recall'].append(metrics['recall'])\n",
        "    \n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"\\nEğitim Loss: {train_loss:.4f}, Eğitim Acc: {train_acc:.4f}\")\n",
        "    print(f\"Doğrulama Loss: {val_loss:.4f}, Doğrulama Acc: {val_acc:.4f}\")\n",
        "    print(f\"Doğrulama AUC-ROC: {metrics['auc_roc']:.4f}, Doğrulama F1-Score: {metrics['f1_score']:.4f}\")\n",
        "    print(f\"Doğrulama Precision: {metrics['precision']:.4f}, Doğrulama Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"Öğrenme Oranı: {current_lr:.6f}\")\n",
        "    \n",
        "    save_model = False\n",
        "    if metrics['auc_roc'] > best_val_auc:\n",
        "        best_val_auc = metrics['auc_roc']\n",
        "        save_model = True\n",
        "        print(f\"✓ AUC-ROC iyileşti! (AUC: {best_val_auc:.4f})\")\n",
        "    \n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        save_model = True\n",
        "        print(f\"✓ Accuracy iyileşti! (Acc: {best_val_acc:.4f})\")\n",
        "    \n",
        "    if save_model:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_acc': val_acc,\n",
        "            'val_auc_roc': metrics['auc_roc'],\n",
        "            'class_names': class_names,\n",
        "            'model_type': 'transfer' if USE_TRANSFER_LEARNING else 'custom',\n",
        "            'model_name': MODEL_NAME if USE_TRANSFER_LEARNING else 'custom'\n",
        "        }, os.path.join(SAVE_DIR, 'best_resnet18_model.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Final Değerlendirme\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nSınıflandırma Raporu:\")\n",
        "print(classification_report(val_labels, val_preds, target_names=class_names))\n",
        "\n",
        "print(\"\\nGrafikler çiziliyor...\")\n",
        "plot_training_history(history, save_path=os.path.join(SAVE_DIR, 'training_history.png'))\n",
        "plot_confusion_matrix(val_labels, val_preds, class_names, \n",
        "                     save_path=os.path.join(SAVE_DIR, 'confusion_matrix.png'))\n",
        "plot_roc_curve(val_labels, val_probs, class_names, \n",
        "              save_path=os.path.join(SAVE_DIR, 'roc_curve.png'))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Final Sonuç Özeti:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"En iyi Accuracy: {best_val_acc:.4f}\")\n",
        "print(f\"En iyi AUC-ROC: {best_val_auc:.4f}\")\n",
        "print(f\"Final F1-Score: {metrics['f1_score']:.4f}\")\n",
        "print(f\"Final Precision: {metrics['precision']:.4f}\")\n",
        "print(f\"Final Recall: {metrics['recall']:.4f}\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n✓ Eğitim başarıyla tamamlandı!\")\n",
        "print(f\"  Model kaydedildi: {os.path.join(SAVE_DIR, 'best_resnet18_model.pth')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Tahmin Fonksiyonları (Prediction Functions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model_for_prediction(checkpoint_path, device):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    \n",
        "    class_names = checkpoint.get('class_names', ['Normal', 'Disease'])\n",
        "    num_classes = len(class_names)\n",
        "    model_type = checkpoint.get('model_type', 'custom')\n",
        "    model_name = checkpoint.get('model_name', 'custom')\n",
        "    \n",
        "    if model_type == 'transfer':\n",
        "        model = create_model(\n",
        "            num_classes=num_classes,\n",
        "            input_channels=3,\n",
        "            pretrained=False,\n",
        "            model_type='transfer',\n",
        "            model_name=model_name,\n",
        "            freeze_backbone=False\n",
        "        )\n",
        "    else:\n",
        "        model = create_model(\n",
        "            num_classes=num_classes,\n",
        "            input_channels=3,\n",
        "            pretrained=False,\n",
        "            model_type='custom'\n",
        "        )\n",
        "    \n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    return model, class_names\n",
        "\n",
        "\n",
        "def preprocess_image(image_path, img_size=224):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                           std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    \n",
        "    return image_tensor, image\n",
        "\n",
        "\n",
        "def predict_image(model, image_tensor, class_names, device):\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        confidence, predicted = torch.max(probabilities, 1)\n",
        "    \n",
        "    predicted_class = class_names[predicted.item()]\n",
        "    confidence_score = confidence.item()\n",
        "    \n",
        "    all_probs = probabilities[0].cpu().numpy()\n",
        "    prob_dict = {class_names[i]: float(all_probs[i]) for i in range(len(class_names))}\n",
        "    \n",
        "    return predicted_class, confidence_score, prob_dict\n",
        "\n",
        "print(\"✓ Tahmin fonksiyonları tanımlandı!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Örnek Tahmin (Example Prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_path = 'checkpoints/best_resnet18_model.pth'\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"Model yükleniyor: {checkpoint_path}\")\n",
        "    model_pred, class_names_pred = load_model_for_prediction(checkpoint_path, device)\n",
        "    print(f\"Model başarıyla yüklendi!\")\n",
        "    print(f\"Mevcut sınıflar: {class_names_pred}\")\n",
        "    \n",
        "    example_image_path = 'IM-0001-0001.jpeg'\n",
        "    \n",
        "    if os.path.exists(example_image_path):\n",
        "        print(f\"\\nGörüntü işleniyor: {example_image_path}\")\n",
        "        image_tensor, original_image = preprocess_image(example_image_path, IMG_SIZE)\n",
        "        \n",
        "        print(\"Tahmin yapılıyor...\")\n",
        "        predicted_class, confidence, all_probs = predict_image(\n",
        "            model_pred, image_tensor, class_names_pred, device\n",
        "        )\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Tahmin Sonuçları:\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Görüntü: {example_image_path}\")\n",
        "        print(f\"Tahmin Edilen Sınıf: {predicted_class}\")\n",
        "        print(f\"Güven Seviyesi: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
        "        print(\"\\nTüm sınıflar için olasılıklar:\")\n",
        "        sorted_probs = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)\n",
        "        for class_name, prob in sorted_probs:\n",
        "            print(f\"  {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(original_image)\n",
        "        plt.title(f'Tahmin: {predicted_class} (Güven: {confidence*100:.2f}%)', fontsize=14)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Görüntü bulunamadı: {example_image_path}\")\n",
        "        print(\"Lütfen geçerli bir görüntü yolu belirtin.\")\n",
        "else:\n",
        "    print(f\"Model dosyası bulunamadı: {checkpoint_path}\")\n",
        "    print(\"Lütfen önce modeli eğitin.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](checkpoints/confusion_matrix.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](checkpoints/training_history.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](<Ekran görüntüsü 2025-12-30 140225.png>)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
