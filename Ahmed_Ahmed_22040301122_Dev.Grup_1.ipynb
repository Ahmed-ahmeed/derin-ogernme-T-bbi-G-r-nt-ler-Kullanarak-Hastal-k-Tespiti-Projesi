{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307ce9d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                            roc_auc_score, roc_curve, f1_score, precision_score, \n",
    "                            recall_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7867f7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MedicalImageCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_channels=3):\n",
    "        super(MedicalImageCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout3 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout4 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout6 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout6(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def create_model(num_classes=2, input_channels=3):\n",
    "    model = MedicalImageCNN(num_classes=num_classes, input_channels=input_channels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58080e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, batch_size=32, img_size=224, use_weighted_sampler=False, num_workers=4):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((int(img_size * 1.1), int(img_size * 1.1))),\n",
    "        transforms.RandomCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.1)\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(data_dir, 'train'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(data_dir, 'val'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    train_sampler = None\n",
    "    class_weights = None\n",
    "    \n",
    "    if use_weighted_sampler:\n",
    "        class_counts = {}\n",
    "        for idx, (path, class_idx) in enumerate(train_dataset.samples):\n",
    "            class_counts[class_idx] = class_counts.get(class_idx, 0) + 1\n",
    "        \n",
    "        total_samples = sum(class_counts.values())\n",
    "        num_classes = len(class_counts)\n",
    "        class_weights = [total_samples / (num_classes * count) for count in class_counts.values()]\n",
    "        \n",
    "        sample_weights = [class_weights[class_idx] for _, class_idx in train_dataset.samples]\n",
    "        train_sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        print(f\"✓ WeightedRandomSampler etkinleştirildi\")\n",
    "        print(f\"  Ağırlıklar: {dict(zip(train_dataset.classes, class_weights))}\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        sampler=train_sampler,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    if not class_weights:\n",
    "        class_counts = {}\n",
    "        for _, class_idx in train_dataset.samples:\n",
    "            class_counts[class_idx] = class_counts.get(class_idx, 0) + 1\n",
    "        total_samples = sum(class_counts.values())\n",
    "        num_classes = len(class_counts)\n",
    "        class_weights = [total_samples / (num_classes * count) for count in class_counts.values()]\n",
    "    \n",
    "    return train_loader, val_loader, train_dataset.classes, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ebedb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc='Validation')\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    if len(np.unique(all_labels)) == 2:\n",
    "        auc_roc = roc_auc_score(all_labels, all_probs[:, 1])\n",
    "    else:\n",
    "        auc_roc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels, all_probs, {\n",
    "        'auc_roc': auc_roc,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a2b47",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path='training_history.png'):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    axes[0, 0].plot(epochs, history['train_loss'], label='Eğitim Loss', marker='o')\n",
    "    axes[0, 0].plot(epochs, history['val_loss'], label='Doğrulama Loss', marker='s')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Eğitim ve Doğrulama Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    axes[0, 1].plot(epochs, history['train_acc'], label='Eğitim Accuracy', marker='o')\n",
    "    axes[0, 1].plot(epochs, history['val_acc'], label='Doğrulama Accuracy', marker='s')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].set_title('Eğitim ve Doğrulama Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    if 'val_auc_roc' in history:\n",
    "        axes[1, 0].plot(epochs, history['val_auc_roc'], label='Doğrulama AUC-ROC', \n",
    "                       marker='s', color='green')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('AUC-ROC')\n",
    "        axes[1, 0].set_title('Doğrulama AUC-ROC')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    if 'val_f1_score' in history:\n",
    "        axes[1, 1].plot(epochs, history['val_f1_score'], label='Validation F1-Score', \n",
    "                       marker='s', color='purple')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('F1-Score')\n",
    "        axes[1, 1].set_title('Validation F1-Score')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    else:\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Eğitim grafiği kaydedildi: {save_path}\")\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path='confusion_matrix.png'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Örnek Sayısı'})\n",
    "    plt.title('Karışıklık Matrisi (Confusion Matrix)')\n",
    "    plt.ylabel('Gerçek Etiket (True Label)')\n",
    "    plt.xlabel('Tahmin Edilen Etiket (Predicted Label)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Karışıklık matrisi kaydedildi: {save_path}\")\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_true, y_probs, class_names, save_path='roc_curve.png'):\n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_probs[:, 1])\n",
    "        auc_score = roc_auc_score(y_true, y_probs[:, 1])\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[1]} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "    else:\n",
    "        for i in range(n_classes):\n",
    "            y_true_binary = (y_true == i).astype(int)\n",
    "            fpr, tpr, _ = roc_curve(y_true_binary, y_probs[:, i])\n",
    "            auc_score = roc_auc_score(y_true_binary, y_probs[:, i])\n",
    "            plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.title('ROC Eğrisi (ROC Curve)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"ROC eğrisi kaydedildi: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d7ef2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'checkpoints/best_model.pth'\n",
    "DATA_DIR = 'data'\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2058f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\nModel yükleniyor: {CHECKPOINT_PATH}\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "\n",
    "class_names = checkpoint.get('class_names', ['Normal', 'Disease'])\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\nModel Bilgileri:\")\n",
    "print(f\"  Model: CNN (MedicalImageCNN)\")\n",
    "print(f\"  Sınıf Sayısı: {num_classes}\")\n",
    "print(f\"  Sınıflar: {class_names}\")\n",
    "print(f\"  En iyi Accuracy: {checkpoint.get('val_acc', 0):.4f}\")\n",
    "print(f\"  En iyi AUC-ROC: {checkpoint.get('val_auc_roc', 0):.4f}\")\n",
    "print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "\n",
    "model = create_model(\n",
    "    num_classes=num_classes,\n",
    "    input_channels=3\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n✓ Model başarıyla yüklendi!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99fdc7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\nModel yükleniyor: {CHECKPOINT_PATH}\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "\n",
    "class_names = checkpoint.get('class_names', ['Normal', 'Disease'])\n",
    "num_classes = len(class_names)\n",
    "model_type = checkpoint.get('model_type', 'custom')\n",
    "model_name = checkpoint.get('model_name', 'custom')\n",
    "\n",
    "print(f\"\\nModel Bilgileri:\")\n",
    "print(f\"  Model Tipi: {model_type}\")\n",
    "print(f\"  Model Adı: {model_name}\")\n",
    "print(f\"  Sınıf Sayısı: {num_classes}\")\n",
    "print(f\"  Sınıflar: {class_names}\")\n",
    "print(f\"  En iyi Accuracy: {checkpoint.get('val_acc', 0):.4f}\")\n",
    "print(f\"  En iyi AUC-ROC: {checkpoint.get('val_auc_roc', 0):.4f}\")\n",
    "print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "\n",
    "if model_type == 'transfer':\n",
    "    model = create_model(\n",
    "        num_classes=num_classes,\n",
    "        input_channels=3,\n",
    "        pretrained=False,\n",
    "        model_type='transfer',\n",
    "        model_name=model_name,\n",
    "        freeze_backbone=False\n",
    "    )\n",
    "else:\n",
    "    model = create_model(\n",
    "        num_classes=num_classes,\n",
    "        input_channels=3,\n",
    "        pretrained=False,\n",
    "        model_type='custom'\n",
    "    )\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n✓ Model başarıyla yüklendi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d34f86",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_path = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "if os.path.exists(test_path):\n",
    "    test_dataset = datasets.ImageFolder(root=test_path, transform=test_transform)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Test verileri yüklendi: {len(test_dataset)} görüntü\")\n",
    "    print(f\"  Sınıflar: {test_dataset.classes}\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    print(\"\\nTest seti üzerinde değerlendirme yapılıyor...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    test_acc = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    test_precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    test_recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    all_probs = np.array(all_probs)\n",
    "    if len(np.unique(all_labels)) == 2:\n",
    "        test_auc = roc_auc_score(all_labels, all_probs[:, 1])\n",
    "    else:\n",
    "        test_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Test Seti Sonuçları:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"AUC-ROC: {test_auc:.4f}\")\n",
    "    print(f\"F1-Score: {test_f1:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall: {test_recall:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nSınıflandırma Raporu:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=test_dataset.classes, \n",
    "                yticklabels=test_dataset.classes)\n",
    "    plt.title('Test Seti - Karışıklık Matrisi', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Gerçek Etiket', fontsize=12)\n",
    "    plt.xlabel('Tahmin Edilen Etiket', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Test klasörü bulunamadı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d870388",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def predict_single_image(image_path, model, class_names, device, img_size=224):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    confidence_score = confidence.item()\n",
    "    \n",
    "    all_probs = probabilities[0].cpu().numpy()\n",
    "    prob_dict = {class_names[i]: float(all_probs[i]) for i in range(len(class_names))}\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(f'Görüntü: {os.path.basename(image_path)}', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    sorted_probs = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    classes = [item[0] for item in sorted_probs]\n",
    "    probs = [item[1] for item in sorted_probs]\n",
    "    \n",
    "    axes[1].barh(classes, probs, color='steelblue')\n",
    "    axes[1].set_xlabel('Olasılık', fontsize=12)\n",
    "    axes[1].set_title(f'Tahmin: {predicted_class} ({confidence_score*100:.2f}%)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlim([0, 1])\n",
    "    \n",
    "    for i, prob in enumerate(probs):\n",
    "        axes[1].text(prob + 0.01, i, f'{prob:.3f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_class, confidence_score, prob_dict\n",
    "\n",
    "print(\"✓ Tahmin fonksiyonu hazır!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e821b83",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_dir = 'test'\n",
    "if os.path.exists(test_dir):\n",
    "    print(\"Test görüntüleri üzerinde tahmin yapılıyor...\\n\")\n",
    "    \n",
    "    for class_name in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            images = [f for f in os.listdir(class_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                for img_name in images[:2]:\n",
    "                    img_path = os.path.join(class_path, img_name)\n",
    "                    print(f\"{'='*70}\")\n",
    "                    print(f\"Görüntü: {img_path}\")\n",
    "                    predicted, confidence, probs = predict_single_image(\n",
    "                        img_path, model, class_names, device\n",
    "                    )\n",
    "                    print(f\"Gerçek Sınıf: {class_name}\")\n",
    "                    print(f\"Tahmin: {predicted} (Güven: {confidence*100:.2f}%)\")\n",
    "                    print(f\"{'='*70}\\n\")\n",
    "else:\n",
    "    print(\"⚠️ Test klasörü bulunamadı.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70fbc8d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROJE ÖZETİ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model: CNN (MedicalImageCNN)\")\n",
    "print(f\"Sınıf Sayısı: {num_classes}\")\n",
    "print(f\"Sınıflar: {class_names}\")\n",
    "print(f\"\\nEğitim Sonuçları (Validation):\")\n",
    "print(f\"  Accuracy: {checkpoint.get('val_acc', 0):.4f}\")\n",
    "print(f\"  AUC-ROC: {checkpoint.get('val_auc_roc', 0):.4f}\")\n",
    "print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "print(f\"\\nModel Dosyası: {CHECKPOINT_PATH}\")\n",
    "print(f\"Grafikler:\")\n",
    "print(f\"  - checkpoints/training_history.png\")\n",
    "print(f\"  - checkpoints/confusion_matrix.png\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f2135",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "image_path = 'test/TURBERCULOSIS/Tuberculosis-660.png'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    confidence, predicted = torch.max(probabilities, 1)\n",
    "\n",
    "predicted_class = class_names[predicted.item()]\n",
    "confidence_score = confidence.item()\n",
    "\n",
    "all_probs = probabilities[0].cpu().numpy()\n",
    "prob_dict = {class_names[i]: float(all_probs[i]) for i in range(len(class_names))}\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Tahmin Sonuçları:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Görüntü: {image_path}\")\n",
    "print(f\"Tahmin Edilen Sınıf: {predicted_class}\")\n",
    "print(f\"Güven Seviyesi: {confidence_score:.4f} ({confidence_score*100:.2f}%)\")\n",
    "print(\"\\nTüm sınıflar için olasılıklar:\")\n",
    "sorted_probs = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for class_name, prob in sorted_probs:\n",
    "    print(f\"  {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(f'Görüntü: {os.path.basename(image_path)}')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "classes = [item[0] for item in sorted_probs]\n",
    "probs = [item[1] for item in sorted_probs]\n",
    "plt.barh(classes, probs, color='steelblue')\n",
    "plt.xlabel('Olasılık')\n",
    "plt.title(f'Tahmin: {predicted_class} ({confidence_score*100:.2f}%)')\n",
    "plt.xlim([0, 1])\n",
    "for i, prob in enumerate(probs):\n",
    "    plt.text(prob + 0.01, i, f'{prob:.4f}', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d729f",
   "metadata": {},
   "source": [
    "![alt text](checkpoints/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4233c",
   "metadata": {},
   "source": [
    "![alt text](checkpoints/training_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94cd84c",
   "metadata": {},
   "source": [
    "![alt text](<Ekran görüntüsü 2025-12-30 140832.png>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
